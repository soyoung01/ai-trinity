from fastapi import APIRouter, HTTPException, status, Query
from src.api.models.request import PercentileRequest
from src.api.models.response import PercentileResponse, ReportRequest
from src.utils.percentile_calculator import PercentileCalculator, create_user_fitness_profile
from src.utils.persona_classifier import classify_persona
from src.utils.llm_reporter import FitnessReportGenerator
from src.config import settings
from pathlib import Path
import logging

router = APIRouter()
logger = logging.getLogger(__name__)

# ì „ì—­ ê³„ì‚°ê¸° ì¸ìŠ¤í„´ìŠ¤ (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ)
calculator = None
report_generator = None

#ë°±ë¶„ìœ„ ê³„ì‚°ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
def get_calculator():
    global calculator
    if calculator is None:
        reference_path = Path(settings.REFERENCE_DATA_PATH)
        if not reference_path.exists():
            logger.error(f"ì°¸ì¡° ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_path}")
            raise FileNotFoundError(f"ì°¸ì¡° ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_path}")
        calculator = PercentileCalculator(str(reference_path))
        logger.info(f"ë°±ë¶„ìœ„ ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ: {reference_path}")
    return calculator

def get_report_generator():
    global report_generator
    if report_generator is None:
        report_generator = FitnessReportGenerator(
            api_key=settings.OPENAI_API_KEY,
            model=settings.OPENAI_MODEL
        )
    return report_generator


@router.post(
    "/score",
    response_model=PercentileResponse,
    status_code=status.HTTP_200_OK,
    tags=["Fitness"]
)
async def calculate_percentile(
    request: PercentileRequest,
    include_llm: bool = Query(True, description="LLM ë¦¬í¬íŠ¸ ìƒì„± ì—¬ë¶€")):
    try:
        logger.info(f"=== ì²´ë ¥ ë¶„ì„ ì‹œì‘ (include_llm={include_llm}) ===")
        
        # ê³„ì‚°ê¸° ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        calc = get_calculator()
        
        # ì‚¬ìš©ì ë°ì´í„° ë³€í™˜
        user_data = {
            'gender': request.gender,
            'age': request.age,
            'bmi': request.bmi,
            'stamina': {
                'plank': request.stamina.plank,
                'push_up': request.stamina.push_up,
                'chair_squat': request.stamina.chair_squat,
                'step_test': request.stamina.step_test,
                'forward_fold': request.stamina.forward_fold,
                'balance': request.stamina.balance
            }
        }
        
        # í”„ë¡œí•„ ìƒì„±
        profile = create_user_fitness_profile(user_data, calc)
        
        # í˜ë¥´ì†Œë‚˜ ë¶„ë¥˜
        persona = classify_persona(profile['percentiles'])
        profile['persona'] = persona
        
        api_percentiles = {}
        for component, data in profile['percentiles'].items():
            api_percentiles[component] = {
                'percentile': data['percentile']
                # grade ì œê±°
            }
        
        api_persona = {
            'name': persona['name'],
            'emoji': persona['emoji'],
            'description': persona['description'],
            'characteristics': persona['characteristics'],
            'recommendation': persona['recommendation']
        }
        
        response_data = {
            "user_info": profile['user_info'],
            "average_score": profile.get('average_score'),
            "percentiles": api_percentiles,
            "persona": api_persona
        }
        
        if include_llm:
            try:
                logger.info("LLM ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")
                report_gen = get_report_generator()
                
                llm_data = {
                    'user_info': profile['user_info'],
                    'percentiles': profile['percentiles'],
                    'persona': persona
                }
                
                llm_report = report_gen.generate_report(
                    data=llm_data,
                    max_tokens=settings.OPENAI_MAX_TOKENS,
                    temperature=settings.OPENAI_TEMPERATURE
                )
                
                response_data["llm_report"] = llm_report
                logger.info(f"LLM ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ ({len(llm_report)}ì)")
                
            except Exception as e:
                logger.error(f"LLM ìƒì„± ì‹¤íŒ¨ (ë°±ë¶„ìœ„ëŠ” ì •ìƒ): {str(e)}")
                response_data["llm_report"] = "ì²´ë ¥ ì¸¡ì •ì„ ì™„ë£Œí–ˆì–´ìš”! ğŸ’ª\n\nê¾¸ì¤€íˆ ìš´ë™í•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”. í™”ì´íŒ…!"
                logger.info("ê¸°ë³¸ ë¦¬í¬íŠ¸ë¡œ ëŒ€ì²´")
        
        logger.info("=== ì²´ë ¥ ë¶„ì„ ì™„ë£Œ ===")
        
        return PercentileResponse(
            status="success",
            data=response_data,
            message="ë°±ë¶„ìœ„ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        )
        
        
    except FileNotFoundError as e:
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì°¸ì¡° ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    
    except ValueError as e:
        logger.error(f"ì…ë ¥ê°’ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ë°±ë¶„ìœ„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )
        

@router.post(
    "/report",
    summary="LLM ê¸°ë°˜ ì²´ë ¥ ì§„ë‹¨ í…ìŠ¤íŠ¸ ìƒì„±"
)
async def generate_fitness_report(request: ReportRequest):
    
    try:
        # ë””ë²„ê¹…: ì‹¤ì œ ë°ì´í„° êµ¬ì¡° í™•ì¸
        logger.info("=== ë°›ì€ ë°ì´í„° êµ¬ì¡° ===")
        logger.info(f"user_info: {request.user_info}")
        logger.info(f"percentiles keys: {request.percentiles.keys()}")
        logger.info(f"persona keys: {request.persona.keys()}")
        logger.info(f"average_score: {request.average_score}")
        
        # ì²« ë²ˆì§¸ percentile ìƒ˜í”Œ ì¶œë ¥
        if request.percentiles:
            first_key = list(request.percentiles.keys())[0]
            logger.info(f"percentiles ìƒ˜í”Œ [{first_key}]: {request.percentiles[first_key]}")
        
        logger.info(f"persona ë‚´ìš©: {request.persona}")
        logger.info("======================")
        
        report_gen = get_report_generator()
        
        llm_data = {
            'user_info': request.user_info,
            'percentiles': request.percentiles,
            'persona': request.persona,
            'average_score': request.average_score
        }
        
        llm_report = report_gen.generate_report(
            data=llm_data,
            max_tokens=settings.OPENAI_MAX_TOKENS,
            temperature=settings.OPENAI_TEMPERATURE
        )
        
        return {
            "status": "success",
            "data": {
                "llm_report": llm_report
            },
            "message": "AI ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        logger.error(f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        
        # ìµœí›„ì˜ fallback
        return {
            "status": "success",
            "data": {
                "llm_report": "ì²´ë ¥ ì¸¡ì •ì„ ì™„ë£Œí–ˆì–´ìš”! ğŸ’ª\n\nê¾¸ì¤€íˆ ìš´ë™í•˜ë©´ ë” ì¢‹ì•„ì§ˆ ê±°ì˜ˆìš”. í™”ì´íŒ…!"
            },
            "message": "ê¸°ë³¸ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        }